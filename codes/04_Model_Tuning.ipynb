{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Airbnb Price Listing Prediction\n",
    "## Part 4 Model Tuning\n",
    "\n",
    "_Authors: Evonne Tham_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, the XGBoost produced a high $R^2$ score of 0.9665 and 7.849000e-01 for the train and validation sets respectively, and an $RMSE$ of 8995.01. Despite this, the model needs to be tuned by narrowing the features from 324 features to a more manageable number so that the model is more generalisable and for inferences about the data to be easily made. \n",
    "\n",
    "This will be done by utilising the features importance, a built-in function in XGBoost, after they have been modelled. This model will be used as the production model in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of this notebook\n",
    "- [1. Import Necessary Libraries and Load Data](#1.-Import-Necessary-Libraries-and-Load-Data)\n",
    "- [2. GridSearch for Hyperparameter Tuning](#2.-GridSearch-for-Hyperparameter-Tuning)\n",
    "    - [2.1. Defining Function for modelling](#2.1-Defining-Function-for-modelling)\n",
    "    - [2.2. Fitting Models](#2.2.-Fitting-Models)\n",
    "- [3. Model Evaluation](#3.-Model-Evaluation)\n",
    "- [4. Re-training the Best Model (XGBoost)](#4.-Re-training-the-Best-Model-(XGBoost))\n",
    "- [5. Feature Selection](#5.-Feature-Selection)\n",
    "    - [5.1. Feature Importances](#5.1.-Feature-Importances)\n",
    "    - [5.2. Dropping Features](#5.2.-Dropping-Features)\n",
    "- [6. Re-training the XGBoost with Selected Features](#6.-Re-training-the-XGBoost-with-Selected-Features)\n",
    "- [7. Learning Curve](#7.-Learning-Curve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score, accuracy_score\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "\n",
    "#Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Listing: 10789 | Total Number of Features: 300\n"
     ]
    }
   ],
   "source": [
    "# Load in Data \n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "#Set id as index \n",
    "train.set_index('id', inplace=True)\n",
    "\n",
    "print(f\"Total Number of Listing: {train.shape[0]} | Total Number of Features: {train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "features = [col for col in train._get_numeric_data().columns if col != 'price' and col != 'id' and col != 'host_id']\n",
    "\n",
    "X = train[features]\n",
    "y = train['price']\n",
    "\n",
    "# Validation Set \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. GridSearch for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Defining Function for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_modeller_val_scorer(classifier): \n",
    "    \n",
    "    '''\n",
    "    takes arguments \"lr\", \"enet\", \"svr\", \"xgb\"\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Model instantiation\n",
    "    clf_lr = LinearRegression()\n",
    "    clf_enet = ElasticNetCV()\n",
    "    clf_svr = SVR()\n",
    "    clf_xgb = XGBRegressor()\n",
    "    \n",
    "    # Building the model pipelines incl. preprocessing where needed \n",
    "    # Setting up the parameter grids\n",
    "    if classifier == \"lr\":\n",
    "        pipe_lr = Pipeline([('rs', RobustScaler()),\n",
    "                             ('clf_lr', clf_lr)])\n",
    "        \n",
    "        param_grid_lr = [{'clf_lr__fit_intercept': [True, False],\n",
    "                          'clf_lr__normalize': [True, False]}]\n",
    "        \n",
    "\n",
    "        gs = GridSearchCV(pipe_lr, \n",
    "                          param_grid_lr, \n",
    "                          cv=5, \n",
    "                          n_jobs=1, \n",
    "                          verbose=1, \n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    elif classifier == \"enet\":\n",
    "        pipe_enet = Pipeline([('rs', RobustScaler()), \n",
    "                             ('clf_enet', clf_enet)])\n",
    "        \n",
    "        param_grid_enet = [{'clf_enet__l1_ratio': [.1, .5, .7, .9, .95, .99, 1],\n",
    "                            'clf_enet__n_alphas': [1,10,100,1000,10000]}]\n",
    "    \n",
    "        gs = GridSearchCV(pipe_enet, \n",
    "                          param_grid_enet, \n",
    "                          cv=5, \n",
    "                          n_jobs=1, \n",
    "                          verbose=1, \n",
    "                          scoring = \"r2\") \n",
    "    \n",
    "        gs.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    elif classifier == \"svr\":\n",
    "        pipe_svr = Pipeline([('rs', RobustScaler()),\n",
    "                             (\"clf_svr\", clf_svr)])\n",
    "\n",
    "        param_grid_svr = [{\"clf_svr__C\":[1,10], \n",
    "                          \"clf_svr__gamma\":[0.001, 0.01, 0.1, 1], \n",
    "                          \"clf_svr__kernel\":('linear', 'rbf')}]  \n",
    "        \n",
    "        gs = GridSearchCV(pipe_svr, \n",
    "                          param_grid_svr, \n",
    "                          cv=5, \n",
    "                          n_jobs=1, \n",
    "                          verbose=1,\n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train, y_train)   \n",
    "        \n",
    "    \n",
    "    elif classifier == \"xgb\":\n",
    "        pipe_xgb = Pipeline([('rs', RobustScaler()),\n",
    "                            (\"clf_xgb\",clf_xgb)])\n",
    "        \n",
    "        param_grid_xgb  = [{\n",
    "            'clf_xgb__gamma':[0, 0.3], \n",
    "            'clf_xgb__learning_rate': [0.05, 0.3], \n",
    "            'clf_xgb__max_depth':[2,3,5], \n",
    "            'clf_xgb__n_estimators': [1000], \n",
    "            'clf_xgb__subsample': [0.05, 0.3, 0.5]\n",
    "        }]\n",
    "                        \n",
    "        gs = GridSearchCV(pipe_xgb, \n",
    "                          param_grid_xgb, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1, \n",
    "                          verbose=1,\n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train, y_train)\n",
    "        \n",
    "    end = time.time()\n",
    "        \n",
    "    #get scores\n",
    "    train_score = gs.score(X_train, y_train)\n",
    "    val_score = gs.score(X_val, y_val)\n",
    "    y_pred = gs.predict(X_val)\n",
    "    \n",
    "    #get R2, MSE Score, RMSE score\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = (mean_squared_error(y_val, y_pred))**0.5\n",
    "    \n",
    "    \n",
    "    \n",
    "    metrics_list= [train_score, val_score, gs.best_score_, r2, mse, rmse]\n",
    "    \n",
    "    # Print out total run time \n",
    "    print(f\"Time taken to run: {round((end - start)/60,1)} minutes\")\n",
    "    print('==================================================================================')\n",
    "    print('')\n",
    "\n",
    "    # print out accuracy, estimator and parameters from GridSearchCV\n",
    "    print(f'Best train accuracy score = {train_score}')\n",
    "    print(f'Best validation accuracy score = {val_score}')\n",
    "    print(f'Best grid search score = {gs.best_score_}')\n",
    "    print(f'R2 score = {r2}')\n",
    "    print(f'Mean Square Error = {mse}')\n",
    "    print(f\"Root mean squared error = {rmse}\")\n",
    "    print('==================================================================================')\n",
    "    print('')\n",
    "    \n",
    "    print(f'Best estimator = {gs.best_estimator_}')\n",
    "    print(f'Best parameters = {gs.best_params_}')\n",
    "    print('==================================================================================')\n",
    "    print('')\n",
    "    \n",
    "    print(f\"metrics list for {classifier}:\", metrics_list)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for Parameters of model\n",
    "# clf_xgb = XGBRegressor()\n",
    "# pipe_xgb = Pipeline([('ss', RobustScaler()),\n",
    "#                             (\"clf_xgb\",clf_xgb)])\n",
    "# pipe_xgb.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 0.1 minutes\n",
      "==================================================================================\n",
      "\n",
      "Best train accuracy score = 0.8304163219962034\n",
      "Best validation accuracy score = -1472075.2379907111\n",
      "Best grid search score = -2170959888198331.2\n",
      "R2 score = -1472075.2379907111\n",
      "Mean Square Error = 629065072969101.9\n",
      "Root mean squared error = 25081169.689013746\n",
      "==================================================================================\n",
      "\n",
      "Best estimator = Pipeline(memory=None,\n",
      "         steps=[('rs',\n",
      "                 RobustScaler(copy=True, quantile_range=(25.0, 75.0),\n",
      "                              with_centering=True, with_scaling=True)),\n",
      "                ('clf_lr',\n",
      "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                                  normalize=False))],\n",
      "         verbose=False)\n",
      "Best parameters = {'clf_lr__fit_intercept': True, 'clf_lr__normalize': False}\n",
      "==================================================================================\n",
      "\n",
      "metrics list for lr: [0.8304163219962034, -1472075.2379907111, -2170959888198331.2, -1472075.2379907111, 629065072969101.9, 25081169.689013746]\n"
     ]
    }
   ],
   "source": [
    "grid_modeller_val_scorer(\"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "grid_modeller_val_scorer(\"enet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_modeller_val_scorer(\"svr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Extreme Gradient Boosting Trees Regressor (\"XGB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_modeller_val_scorer(\"xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Evaluation\n",
    "The evaluation metrics used will be mean squared error (for loss) and r squared (for accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list= [\"train_score\", \"val_score\", \"gs.best_score_\", \"r2\", \"mse\", \"rmse\"]\n",
    "\n",
    "lr = [0.3874269279942756, -1.1662068491359909e+17, \n",
    "      -1.7179846319682506e+16, -1.1662068491359909e+17, \n",
    "      4.865832573216899e+25, 6975552001968.661]\n",
    "    \n",
    "enet = [0.3735451842108308, 0.35577415679938695, \n",
    "        0.3441756543727746, 0.35577415679938695, \n",
    "        268794090.4030937, 16394.94100029316]\n",
    "\n",
    "svr = [0.09799514764047101, 0.09759825210558948, \n",
    "       0.08737507533950861, 0.09759825210558948, \n",
    "       376514322.6765994, 19403.97698093356]\n",
    "\n",
    "xgb = [0.9665104649768522, 0.7849005858043501, \n",
    "       0.7623192112420136, 0.7849005858043501, \n",
    "       80910129.01162435, 8995.005781633738]\n",
    "\n",
    "\n",
    "eval_data = [lr, enet, svr, xgb]\n",
    "\n",
    "column_names = metrics_list\n",
    "\n",
    "index = [\"Linear Regression\", \"ElasticNetCV\", \"Support Vector Regressor\", \"XGBoost\"]\n",
    "\n",
    "eval_df = pd.DataFrame(eval_data, columns=column_names, index=index)\n",
    "    \n",
    "eval_df = eval_df.round(decimals = 4)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this table and our particular output reproduced above, we can see that linear regression performed the worst as the train set has a $R^2$ of 0.3874 and -1.166207e+17 on the validation set. This shows that the model is arbitrarily worse as it does not follow the trend of the data.\n",
    "\n",
    "Support Vector Machine and ElasticNet performed poorly, eventhough there's not much difference between the $R^2$ score of 0.098 and 0.3735 on train set and $R^2$ score of 0.0976 and 0.3558 on validation set respectively. \n",
    "\n",
    "Hence the clear winner is eXtreme Gradient Boosting. It has the highest $R^2$ of 0.785 on the entire validation set means that our model is able to account for almost 80% of the variance in the target variable. With a $RMSE$ score of 8995.01, what this means is that our model's prediction is on average off by 8995¥ in terms of predicting the property's price. This is pretty good for a preliminary model using regression techniques.\n",
    "\n",
    "***The best parameters are:*** \n",
    "- gamma: 0, \n",
    "- learning_rate: 0.05, \n",
    "- max_depth: 5, \n",
    "- n_estimators: 1000, \n",
    "- subsample: 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Re-training the Best Model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "features = [col for col in train._get_numeric_data().columns if col != 'price' and col != 'id' and col != 'host_id']\n",
    "X = train[features]\n",
    "y = train['price']\n",
    "\n",
    "# Train/Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state = 42) \n",
    "\n",
    "rs = RobustScaler()\n",
    "X_train_rs = rs.fit_transform(X_train)\n",
    "X_val_rs = rs.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Best Model\n",
    "xgb = XGBRegressor(gamma = 0,\n",
    "                   learning_rate = 0.05, \n",
    "                   max_depth = 5, \n",
    "                   n_estimators = 1000, \n",
    "                   subsample = 0.3)\n",
    "\n",
    "# Fit Model\n",
    "xgb.fit(X_train_rs, y_train)\n",
    "\n",
    "#Predict target values\n",
    "pred = xgb.predict(X_val_rs)\n",
    "residuals = y_val - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Residuals\n",
    "# plt.figure(figsize=(15,8))\n",
    "\n",
    "# plt.scatter(pred, residuals)\n",
    "# plt.axhline(0, linestyle='-', color='r')\n",
    "# plt.title('Residual distribution plot for XGBoost regression', fontsize=14)\n",
    "# plt.xlabel('Predicted values', fontsize=12)\n",
    "# plt.ylabel('Residuals', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing top features in our production model. \n",
    "key_features = pd.DataFrame([xgb.feature_importances_], columns = X.columns).T\n",
    "key_features.sort_values(0, ascending = False, inplace = True)\n",
    "key_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10,50))\n",
    "plt.barh(key_features.index, key_features[0], align='center') \n",
    "plt.title(\"Feature importances in the XGBoost model\", fontsize=20)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.margins(y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "About a good number of features have a feature importance of 0 in this XGBoost regression model, and could potentially be removed.\n",
    "\n",
    "The top 10 most important features are:\n",
    "\n",
    "\n",
    "The most important features the rental being the entire flat. Which makes sense. Asking price is higher if the offer is for the entire flat/house. This could also suggest that offering the flat/house as a whole, rather than each bedroom individually, may be better overall, given the large difference in importance compared to the second most important feature.\n",
    "\n",
    "It is not surprising that the second how many people the property accommodates, as that's one of the main things you would use to search for properties with in the first place.\n",
    "\n",
    "It is perhaps more surprising that location features did not appear in the top ten. Although we can observe that belonging to a certain neighbourhood increases price more than others and Score (accessibility measure) also shows some importance, they are of relative low importance compared to the top 3 features. Review Scores Location is higher on the importance list (number 11). This is, it is likely renters put more weight in other's opinion about location instead of judging the location based on neighbourhood and venues around the property. This could also be because Edinburgh is a small and walkable city with good transportation services. Thus, location is not a major problem to reaching main touristic attractions and amenities.\n",
    "\n",
    "The eight most important feature is related to how many other listings the host manages on Airbnb, rather than the listing itself. This result showed on this analysis of Airbnb listings in London, only this feature was the third most important. What the researcher (and former data scientists at an Airbnb management company) explains is that this does not mean that a host that manages more properties will result in a listing gaining higher prices, and could be due to experienced hosts setting higher prices. Also, it could be that big Airbnb management companies that have lots of listings tend to manage more expensive properties than single listing hosts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Re-training the XGBoost with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "# %matplotlib inline\n",
    "\n",
    "# def plot_learning_curve(estimator, clf, X, y, ylim=None, cv=None, train_sizes=None):\n",
    "#     plt.figure()\n",
    "#     plt.title(f'Learning Curves ({clf})')\n",
    "#     plt.ylim(*ylim)\n",
    "#     plt.xlabel(\"Training examples\")\n",
    "#     plt.ylabel(\"Score\")\n",
    "#     train_sizes, train_scores, test_scores = learning_curve(\n",
    "#         estimator, X, y, cv=cv, train_sizes=train_sizes)\n",
    "#     train_scores_mean = np.mean(train_scores, axis=1)\n",
    "#     train_scores_std = np.std(train_scores, axis=1)\n",
    "#     test_scores_mean = np.mean(test_scores, axis=1)\n",
    "#     test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "#     plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "#                      color=\"r\")\n",
    "#     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "#     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "#              label=\"Training score\")\n",
    "#     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "#              label=\"Cross-validation score\")\n",
    "\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     plt.grid(True)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sizes = np.linspace(.1, 1.0, 5)\n",
    "# ylim = (0.9, 1.01)\n",
    "# cv = 5\n",
    "\n",
    "# plot_learning_curve(pipe_lr, \"Linear Regression\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_enet, \"ElasticNetCV\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_svr, \"SVR\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_xgb, \"XGBoost\", X_val, y_val,\n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----> Proceed to the next notebook for [Production Model](./05_Production_Model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
