{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Airbnb Price Listing Prediction\n",
    "## Part 4 Model Tuning\n",
    "\n",
    "_Authors: Evonne Tham_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, the XGBoost produced a high r2 score of _[]_ and 0.908 for the train and validation sets respectively, and an RMSE of _[]_. Despite this, the model needs to be tuned by narrowing the features from _[]_ features to a more manageable number so that the model is more generalisable and for inferences about the data to be easily made. \n",
    "\n",
    "This will be done by utilising the features' importance, a build in function in XGBoost, after they have been modelled. This model will be used as the production model in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of this notebook\n",
    "1. [Import Necessary Libraries and Load Data](#1.-Import-Necessary-Libraries-and-Load-Data)\n",
    "2. [Re-training the Best Model (XGBoost)](#2.-Re-training-the-Best-Model-(XGBoost))\n",
    "3. [Feature Selection](#3.-Feature-Selection)\n",
    "4. [Re-training the XGBoost with Selected Features](#4.-Re-training-the-XGBoost-with-Selected-Features) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score, accuracy_score\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "\n",
    "#Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Data \n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "# #Set id as index \n",
    "# df.set_index('id', inplace=True)\n",
    "\n",
    "print(f\"Total Number of Listing: {train.shape[0]} | Total Number of Features: {train.shape[1]}\")\n",
    "train.head(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Re-training the Best Model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "features = [col for col in train._get_numeric_data().columns if col != 'price']\n",
    "X = train[features]\n",
    "y = train['price']\n",
    "\n",
    "# Train/Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state = 42) \n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Best Model\n",
    "xgb = XGBClassifier(gamma = 0.3, \n",
    "                    learning_rate = 0.1, \n",
    "                    max_depth = 5, \n",
    "                    n_estimators = , \n",
    "                    reg_alpha = , \n",
    "                    reg_lambda = ,\n",
    "                    subsample = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option 1 \n",
    "# # ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train.columns)\n",
    "# # ft_weights_xgb_reg.sort_values('weight', ascending=False, inplace=True)\n",
    "# # ft_weights_xgb_reg.head(10)\n",
    "\n",
    "# # option 2\n",
    "# #Visualizing top features in our production model. \n",
    "# features = xgb.feature_importances_\n",
    "# key_features = pd.Series(features, index=X.columns)\n",
    "# sorted_features = key_features.sort_values(ascending=False).head(30)\n",
    "# sorted_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing top features in our production model. \n",
    "key_features = pd.DataFrame([xgb.feature_importances_], columns = X.columns).T\n",
    "key_features.sort_values('weight', ascending = False, inplace = True)\n",
    "key_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "plt.figure(figsize=(15,25))\n",
    "plt.barh(key_features.index, key_features.weight, align='center') \n",
    "plt.title(\"Feature importances in the XGBoost model\", fontsize=20)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.margins(y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Re-training the XGBoost with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Leanring Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "# %matplotlib inline\n",
    "\n",
    "# def plot_learning_curve(estimator, clf, X, y, ylim=None, cv=None, train_sizes=None):\n",
    "#     plt.figure()\n",
    "#     plt.title(f'Learning Curves ({clf})')\n",
    "#     plt.ylim(*ylim)\n",
    "#     plt.xlabel(\"Training examples\")\n",
    "#     plt.ylabel(\"Score\")\n",
    "#     train_sizes, train_scores, test_scores = learning_curve(\n",
    "#         estimator, X, y, cv=cv, train_sizes=train_sizes)\n",
    "#     train_scores_mean = np.mean(train_scores, axis=1)\n",
    "#     train_scores_std = np.std(train_scores, axis=1)\n",
    "#     test_scores_mean = np.mean(test_scores, axis=1)\n",
    "#     test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "#     plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "#                      color=\"r\")\n",
    "#     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "#     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "#              label=\"Training score\")\n",
    "#     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "#              label=\"Cross-validation score\")\n",
    "\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     plt.grid(True)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sizes = np.linspace(.1, 1.0, 5)\n",
    "# ylim = (0.9, 1.01)\n",
    "# cv = 5\n",
    "\n",
    "# plot_learning_curve(pipe_lr, \"Linear Regression\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_enet, \"ElasticNetCV\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_svr, \"SVR\", X_val, y_val, \n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "# plot_learning_curve(pipe_xgb, \"XGBoost\", X_val, y_val,\n",
    "#                     ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----> Proceed to the next notebook for [Production Model](./05_Production_Model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
