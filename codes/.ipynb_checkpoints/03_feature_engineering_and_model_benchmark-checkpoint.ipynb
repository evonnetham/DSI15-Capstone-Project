{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Airbnb Price Listing Prediction\n",
    "## Part 3 Feature Engineering & Model Benchmark\n",
    "\n",
    "_Authors: Evonne Tham_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Import Necessary Libraries & Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Model Selection - fixed learning method</b>\n",
    "\n",
    "- Split the data into train, test, and validation.\n",
    "- Train as many models as there are hyperparameter combinations on the train set.\n",
    "- Evaluate each of these models on the validation set.\n",
    "- Select the model with the best performance on the validation set.\n",
    "- Retrain the model on the combined train + validation sets using 'winning' hyperparameter combination.\n",
    "- Estimate generalisation performance on the test set. If the test error is similar to the validation error then we have belief that this model will generalise well to unseen data.\n",
    "- Finally retrain the model with the choosen hyperparameters on the entire set before production.\n",
    "\n",
    "<b>Algorithm Selection</b>\n",
    "\n",
    "We can follow the above reasoning but split the data into independent train, validation, test sets for each learning method we are testing.\n",
    "This obviously only works if we have a large amount of data at our disposal.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "# from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score, accuracy_score\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "\n",
    "#Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Data \n",
    "df = pd.read_csv('../datasets/final_df.csv')\n",
    "print(f\"Total Number of Listing: {df.shape[0]} | Total Number of Features: {df.shape[1]}\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "# from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score, accuracy_score\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "\n",
    "#Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load in Data \n",
    "df = pd.read_csv('../datasets/final_df.csv')\n",
    "print(f\"Total Number of Listing: {df.shape[0]} | Total Number of Features: {df.shape[1]}\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['property_type',\n",
    "                                 'room_type',\n",
    "                                 'cancellation_policy',\n",
    "                                 'neighbourhood',\n",
    "                                 'host_response_time',\n",
    "                                 'host_acceptance_rate',\n",
    "                                 'review_scores_rating',\n",
    "                                 'review_scores_accuracy',\n",
    "                                 'review_scores_cleanliness',\n",
    "                                 'review_scores_checkin',\n",
    "                                 'review_scores_communication',\n",
    "                                 'review_scores_location',\n",
    "                                 'review_scores_value',\n",
    "                                 'instant_bookable',\n",
    "                                 'is_location_exact'\n",
    "                                ], \n",
    "                         drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amenities = df['amenities'].str.get_dummies(sep=',')\n",
    "df = pd.concat([df, all_amenities], axis=1)\n",
    "\n",
    "print(f\"Total Number of Listing: {df.shape[0]} | Total Number of Features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,100))\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "corr = df.corr()\n",
    "\n",
    "sns.heatmap(df.corr()[['price']].sort_values(by='price', ascending=False), \n",
    "            cmap=cmap, \n",
    "            center=0, \n",
    "            annot=True,\n",
    "            cbar_kws={\"shrink\": .9},)\n",
    "\n",
    "plt.title('Correlation Between Amenities and Price', fontsize=20)\n",
    "y_min, y_max = ax.get_ylim() \n",
    "x_min, x_max = ax.get_xlim()\n",
    "ax.set_ylim(top=y_max+1) \n",
    "ax.set_xlim(right=x_max-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, \n",
    "            mask=mask, \n",
    "            cmap=cmap, \n",
    "            center=0, \n",
    "            square=True, \n",
    "            linewidths=.5, \n",
    "            cbar_kws={\"shrink\": .5})\n",
    "\n",
    "ax.set_title('Collinearity between Features', fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  3. Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Create X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df._get_numeric_data().columns if col != 'price']\n",
    "\n",
    "X = df[features]\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  ii. Baseline Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The mean value of the target vector is: {np.mean(y)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Observation:</b> Without any regression modelling, the predicted value for every data point is 17990Â¥.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_ss = ss.transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv. Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_constant = DummyRegressor(strategy='constant', constant = 17990.367118495848 )\n",
    "dummy_constant.fit(X_train_ss, y_train)\n",
    "print(f'R2 score for baseline model: {dummy_constant.score(X_train_ss, y_train)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Observation:</b> This is a bad r2 score as it indicates that the baseline model explains basically none of the variability of the response data around its mean.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Regression Models\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lasso = LassoCV(n_alphas=200)\n",
    "\n",
    "ridge = RidgeCV(alphas=np.linspace(.1, 10, 100))\n",
    "\n",
    "enet = ElasticNetCV(l1_ratio=np.linspace(0.001, 1, 50), n_alphas = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a K Fold cross validation for Models \n",
    "# The bigger the score the better the model.\n",
    "\n",
    "print(\"Accuracy of Linear Regression Model with Cross-Validation: {}\".format(cross_val_score(lr, \n",
    "                                                                                             X_train_ss, \n",
    "                                                                                             y_train, \n",
    "                                                                                             cv=5, \n",
    "                                                                                             scoring='r2').mean()))\n",
    "print('*********************************************************************************')\n",
    "\n",
    "print(\"Accuracy of Lasso Model with Cross-Validation: {}\".format(cross_val_score(lasso, \n",
    "                                                                                 X_train_ss, \n",
    "                                                                                 y_train, \n",
    "                                                                                 cv=5, \n",
    "                                                                                 scoring='r2').mean()))\n",
    "print('*********************************************************************************')\n",
    "\n",
    "print(\"Accuracy of Ridge Model with Cross-Validation: {}\".format(cross_val_score(ridge, \n",
    "                                                                                 X_train_ss, \n",
    "                                                                                 y_train, \n",
    "                                                                                 cv=5, \n",
    "                                                                                 scoring='r2').mean()))\n",
    "print('*********************************************************************************')\n",
    "\n",
    "print(\"Accuracy of Elastic Net Model with Cross-Validation: {}\".format(cross_val_score(enet, \n",
    "                                                                                       X_train_ss,\n",
    "                                                                                       y_train, \n",
    "                                                                                       cv=5, \n",
    "                                                                                       scoring='r2').mean()))\n",
    "\n",
    "print('')\n",
    "print('Cross Validation Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "##  4. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_modeller_val_scorer(regressor): \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Hyperparameter tuning that takes arguments \"knn\", \"rf\", \"gb\", \"xgb\" \"svc\"\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #all 5 regressor models correspond respectively to these 5 instantiated models:\n",
    "    lr = LinearRegression()\n",
    "    lasso = LassoCV()\n",
    "    ridge = RidgeCV()\n",
    "    enet = ElasticNetCV()\n",
    "    knn = KNeighborsRegressor()\n",
    "    rf  = RandomForestRegressor()\n",
    "    gb = GradientBoostingRegressor()\n",
    "    xgb = XGBRegressor()\n",
    "    \n",
    "    if regressor == \"knn\":\n",
    "        pipe_knn = Pipeline([('scaler', RobustScaler()), \n",
    "                             ('knn', knn)])\n",
    "        \n",
    "        param_grid_knn = {'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                          'knn__p': [1, 2],\n",
    "                          'knn__leaf_size': [10, 20, 30, 40, 50]}\n",
    "\n",
    "        gs = GridSearchCV(pipe_knn, \n",
    "                          param_grid_knn, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1, \n",
    "                          verbose=1, \n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train_ss, y_train)\n",
    "    \n",
    "    elif regressor == \"rf\":\n",
    "        \n",
    "        #run grid search on Random Forest params:\n",
    "        param_grid_rf  = [{'n_estimators': [10, 50, 100, 250, 500, 1000],\n",
    "                           'min_samples_leaf': [1, 3, 5],\n",
    "                           'max_features': ['sqrt', 'log2'], \n",
    "                           'class_weight':[{0: w} for w in [1, 2, 4, 6, 10]]}] \n",
    "                            #another class re-weighting attempt\n",
    "    \n",
    "        gs = GridSearchCV(rf, \n",
    "                          param_grid_rf, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1, \n",
    "                          verbose=1, \n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train_ss, y_train)\n",
    "                            \n",
    "    elif regressor == \"gb\":\n",
    "        \n",
    "        #create Gradient Boosting pipeline:\n",
    "        pipe_gb = Pipeline([('scaler', RobustScaler()),\n",
    "                            (\"gb\", gb)])\n",
    "        \n",
    "        #run grid search on Gradient Boosting Params\n",
    "        param_grid_gb = [{'gb__max_depth': [2,3,4,5],\n",
    "                          'gb__n_estimators': [100, 125, 150, 200],\n",
    "                          'gb__learning_rate': [.08, .1, .12]}]\n",
    "    \n",
    "        gs = GridSearchCV(pipe_gb, \n",
    "                          param_grid_gb, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1, \n",
    "                          verbose=1,\n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train_ss, y_train)\n",
    "    \n",
    "    elif regressor == \"xgb\":\n",
    "        \n",
    "        #create Gradient Boosting pipeline:\n",
    "        pipe_xgb = Pipeline([('scaler', RobustScaler()),\n",
    "                             (\"xgb\", xgb)])\n",
    "        \n",
    "        #run grid search on Xtreme Gradient Boosting Params\n",
    "        param_grid_xgb = [{'xgb__max_depth': [2,3,4,5,6,7,8,9,10],\n",
    "                           'xgb__n_estimators': [100, 125, 150, 200, 250],\n",
    "                           'xgb__learning_rate': [.1, .01, .05],\n",
    "                           'xgb__scale_pos_weight':list(range(18,52,2))}]\n",
    "                        \n",
    "        gs = GridSearchCV(pipe_xgb, \n",
    "                          param_grid_xgb, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1, \n",
    "                          verbose=1,\n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train_ss, y_train)\n",
    "                            \n",
    "    elif regressor == \"svc\":\n",
    "        \n",
    "        #create SVM pipeline for classification and scaling\n",
    "        pipe_svm = Pipeline([('scaler', RobustScaler()),\n",
    "                             (\"svc\", svc)])\n",
    "        \n",
    "        #run grid search on SVC paramaters\n",
    "        param_grid_svm = {\"svc__C\":[1,10], \"clf_svc__gamma\":[0.001, 0.01, 0.1, 1], \n",
    "                          \"svc__kernel\":('linear', 'rbf','sigmoid','poly')}  \n",
    "        \n",
    "        gs = GridSearchCV(pipe_svm, \n",
    "                          param_grid_svm, \n",
    "                          cv=5, \n",
    "                          n_jobs=-1,\n",
    "                          verbose=1,\n",
    "                          scoring = \"r2\") \n",
    "        \n",
    "        gs.fit(X_train_ss, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get scores\n",
    "    train_score = gs.score(X_train_ss, y_train)\n",
    "    val_score = gs.score(X_val, y_val)\n",
    "        \n",
    "    #get confusion matrix and classification metrics\n",
    "    y_pred = gs.predict(X_val)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"pred_WNV\",\"pred_no_WNV\"], index=[\"actual_WNV\",\"actual_no_WNV\"])\n",
    "        \n",
    "#     #get ROC AUC and F1 Score\n",
    "#     auc = roc_auc_score(y_val, y_pred)\n",
    "#     f1_score = metrics.f1_score(y_val, y_pred)\n",
    "#     precision = metrics.precision_score(y_val, y_pred)\n",
    "#     recall = metrics.recall_score(y_val, y_pred)\n",
    "    \n",
    "    metrics_list= [train_score, val_score, gs.best_score_, auc, f1_score, precision, recall]\n",
    "\n",
    "    \n",
    "    #print out accuracy, estimator and parameters from GridSearchCV\n",
    "    print(f'best train accuracy score = {train_score}')\n",
    "    print(f'best validation accuracy score = {val_score}')\n",
    "    print(f'best grid search score = {gs.best_score_}')\n",
    "    print(f'ROC AUC score = {auc}')\n",
    "    print(f'f1_score={f1_score}')\n",
    "    print(f\"Precision - ability not to label as positive a sample that is negative = {precision}\")\n",
    "    print(f\"Sensitivity or Recall - ability to find all the positive samples = {recall}\")\n",
    "    print(f'best estimator = {gs.best_estimator_}')\n",
    "    print(f'best parameters = {gs.best_params_}')\n",
    "    print(f\"metrics list for {classifier}:\", metrics_list)\n",
    "\n",
    "    #prints confusion matrix\n",
    "    return cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----> Proceed to the next notebook for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='background:yellow'> 1. Import Necessary Libraries & Load Data </span>  --- to break notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# # modelling\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "# from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "# from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "# from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score, accuracy_score\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "\n",
    "#Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load in Data \n",
    "df = pd.read_csv('../datasets/final_df.csv')\n",
    "print(f\"Total Number of Listing: {df.shape[0]} | Total Number of Features: {df.shape[1]}\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics used will be mean squared error (for loss) and r squared (for accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
